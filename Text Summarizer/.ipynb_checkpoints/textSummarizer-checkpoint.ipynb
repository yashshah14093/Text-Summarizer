{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "    # removing special characters and extra whitespaces\n",
    "    for sentence in article:\n",
    "        sentence = re.sub('[^a-zA-Z]',' ',str(sentence))\n",
    "        sentence = re.sub('[\\s+]',' ', sentence)\n",
    "        sentences.append(sentence)\n",
    "    sentences.pop()\n",
    "    display = \" \".join(sentences)\n",
    "    print('Initial Text: ')\n",
    "    print(display)\n",
    "    print('\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Words in Each Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(sent):\n",
    "    count = 0\n",
    "    words = word_tokenize(sent)\n",
    "    for word in words:\n",
    "        count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data about each sentence (frequency of words)\n",
    "def count_in_sentence(sentences):\n",
    "    txt_data = []\n",
    "    for index,sentence in enumerate(sentences):\n",
    "        count = count_words(sentence)\n",
    "        temp = {'id' : index, 'word_cnt' : count}\n",
    "        txt_data.append(temp)\n",
    "    return txt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating List of Frequencies for each Word in all Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dict(sentences):\n",
    "    freq_list = []\n",
    "    for index,sentence in enumerate(sentences):\n",
    "        freq_dict = {}\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            freq_dict[word] = freq_dict.get(word,0) + 1\n",
    "        temp = {'id' : index, 'freq_dict' : freq_dict}\n",
    "        freq_list.append(temp)\n",
    "    return freq_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating TF and IDF Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_TF(text_data, freq_list):\n",
    "    tf_scores = []\n",
    "    for item in freq_list:\n",
    "        ID = item['id']\n",
    "        for key,value in item['freq_dict'].items():\n",
    "            temp = {\n",
    "                'id': item['id'],\n",
    "                'tf_score': value/text_data[ID]['word_cnt'],\n",
    "                'key': key\n",
    "            }\n",
    "            tf_scores.append(temp)\n",
    "    return tf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IDF(text_data, freq_list):\n",
    "    idf_scores = []\n",
    "    for index,item in enumerate(freq_list):\n",
    "        for key in item['freq_dict']:\n",
    "            val = sum([k in it['freq_dict'] for it in freq_list])\n",
    "            temp = {\n",
    "                'id':index,\n",
    "                'idf_score': math.log(len(text_data)/(val+1)),\n",
    "                'key': key\n",
    "            }\n",
    "            idf_scores.append(temp)\n",
    "    return idf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating TF-IDF Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_TFIDF(tf_scores,idf_scores):\n",
    "    tfidf_scores = []\n",
    "    for idf in idf_scores:\n",
    "        for tf in tf_scores:\n",
    "            if(idf['key'] == tf['key'] and idf['id'] == tf['id']):\n",
    "                temp = {\n",
    "                    'id': idf['id'],\n",
    "                    'tfidf_score': idf['idf_score']*tf['tf_score'],\n",
    "                    'key': idf['key']\n",
    "                }\n",
    "                tfidf_scores.append(temp)\n",
    "    return tfidf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking all the Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_scores(tfidf_scores, sentences, text_data):\n",
    "    sent_data = []\n",
    "    for txt in text_data:\n",
    "        score = 0 \n",
    "        for index in range(len(tfidf_scores)):\n",
    "            t_dict = tfidf_scores[index]\n",
    "            if(txt['id'] == t_dict['id']):\n",
    "                score = score + t_dict['tfidf_score']\n",
    "        temp = {\n",
    "            'id': txt['id'],\n",
    "            'score': score,\n",
    "            'sentence': sentences[txt['id']]\n",
    "        }\n",
    "        sent_data.append(temp)\n",
    "    return sent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(sent_data):\n",
    "    count = 0\n",
    "    summary = []\n",
    "    for t_dict in sent_data:\n",
    "        count = count + t_dict['score']\n",
    "    avg = count / len(sent_data)\n",
    "    for sent in sent_data:\n",
    "        if(sent['score'] >= avg*0.9):\n",
    "            summary.append(sent['sentence'])\n",
    "    summary = \". \".join(summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Text: \n",
      "Napoleon Hill is the most famous conman you ve probably never heard of Born into poverty in rural Virginia at the end of the   th century  Hill went on to write one of the most successful self help books of the   th century  Think and Grow Rich In fact  he helped invent the genre But it s the untold story of Hill s fraudulent business practices  tawdry sex life  and membership in a New York cult that makes him so fascinating That cult would become infamous in the late     s for trying to raise an  immortal baby   But even those who know the story of Immortal Baby Jean may not know that the cult was inspired by Hill s teachings  practically using his most famous work as their holy text Don t worry  the whole story of Napoleon Hill only gets weirder from there Modern readers are probably familiar with the      sensation The Secret  but the concepts in that book were essentially plagiarized from Napoleon Hill s      classic Think and Grow Rich  which has reportedly sold over    million copies to date The big idea in both  The material universe is governed quite directly by our thoughts If you simply visualize what you want out of life  those things and more will be delivered to you Especially if those things involve money The past few decades have been a profitable era for all sorts of self help and business success books Napoleon Hill blazed a trail for an entire industry But Napoleon s early work is seen as  the source  when people get deep into self help and business success literature Hill s Think and Grow Rich is passed around in certain business and real estate circles like some kind of ancient text In fact  when The Secret emerged on the scene in the mid     s  countless entrepreneurial writers would pen their own books  pointing to the works of Napoleon Hill as the true basis for what The Secret called the Law of Attraction You can see the influence of Hill in everything from the success sermons of Tony Robbins to the crooked business dealings of Trump University In fact  you can draw a direct line to Donald Trump s way of thinking through Norman Vincent Peale  an ardent follower of Napoleon Hill Reverend Peale  author of the      book The Power of Positive Thinking  was Donald Trump s pastor as a child The legend of Napoleon Hill has grown and morphed over the years He really did live an extraordinary life  just not the life that his thousands of disciples over the years have claimed It s just too bad that Hill spent most of his life as an utter fraud a fraud who by hook and by crook was constantly reinventing himself Napoleon Hill s Wikipedia page sometimes warns that it s written like an advertisement Which pretty much hits the nail on the head Hill s entire life was an advertisement  one that spoke of honor and taught that if people visualized their dreams and narrowed down their own purpose in life  good things would come to them And if the lessons in Hill s writings  work  for some people  I say good for them I m not here to say that there s nothing to be learned from some of Hill s writings especially those that speak of self confidence  being kind to others  and going the extra mile for something you believe in But the real story behind Napoleon Hill s life is long past due After countless hours of research  I still feel like I ve captured just a mere glimpse of the complex man that was Napoleon Hill\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ca86cf7fc9c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfreq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_TF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0midf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_IDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtfidf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_TFIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-120c9e7a1764>\u001b[0m in \u001b[0;36mcalc_IDF\u001b[0;34m(text_data, freq_list)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq_dict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             temp = {\n\u001b[1;32m      7\u001b[0m                 \u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-120c9e7a1764>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq_dict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             temp = {\n\u001b[1;32m      7\u001b[0m                 \u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = clean_text('input.txt')\n",
    "text_data = count_in_sentence(sentences)\n",
    "\n",
    "freq_list = freq_dict(sentences)\n",
    "tf_scores = calc_TF(text_data, freq_list)\n",
    "idf_scores = calc_IDF(text_data, freq_list)\n",
    "\n",
    "tfidf_scores = calc_TFIDF(tf_scores, idf_scores)\n",
    "\n",
    "sent_data = sent_scores(tfidf_scores, sentences, text_data)\n",
    "result = summary(sent_data)\n",
    "\n",
    "print('SUMMARY:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
